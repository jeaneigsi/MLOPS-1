"""
gradio_app.py - Interface utilisateur Gradio pour la classification d'images

Ce script :
1. Charge le mod√®le depuis un chemin local ou le Model Registry ClearML
2. Cr√©e une interface Gradio pour la pr√©diction
3. Collecte le feedback utilisateur et sauvegarde les images annot√©es
4. Log les pr√©dictions et feedbacks dans ClearML

Usage:
    python src/gradio_app.py
    
    # Avec un mod√®le sp√©cifique:
    python src/gradio_app.py --model-path models/best_model.pth
    
    # Avec le Model Registry ClearML:
    python src/gradio_app.py --use-registry
"""

import argparse
from pathlib import Path
from datetime import datetime
from typing import Optional, Tuple, List

import torch
import gradio as gr
from PIL import Image

from clearml import Task, InputModel

from utils import (
    load_model,
    create_model,
    preprocess_image,
    get_latest_model_path,
    save_feedback_image,
    get_total_feedback_count,
    count_feedback_images,
    get_device,
    setup_clearml_credentials,
    CLEARML_PROJECT_NAME,
    MODELS_DIR,
    FEEDBACK_DIR,
    DEFAULT_CLASSES
)


# =============================================================================
# VARIABLES GLOBALES
# =============================================================================

# Ces variables seront initialis√©es au d√©marrage
MODEL = None
CLASSES = DEFAULT_CLASSES
DEVICE = "cpu"
TASK = None


def parse_args():
    """Parse les arguments de la ligne de commande."""
    parser = argparse.ArgumentParser(description="Application Gradio pour la classification d'images")
    parser.add_argument(
        "--model-path", type=str, default=None,
        help="Chemin vers le mod√®le local (.pth)"
    )
    parser.add_argument(
        "--use-registry", action="store_true",
        help="Charger le mod√®le depuis le Model Registry ClearML"
    )
    parser.add_argument(
        "--model-name", type=str, default="baseline_model_resnet18",
        help="Nom du mod√®le dans le Registry (si --use-registry)"
    )
    parser.add_argument(
        "--share", action="store_true",
        help="Cr√©er un lien public Gradio"
    )
    parser.add_argument(
        "--port", type=int, default=7860,
        help="Port pour l'interface web (default: 7860)"
    )
    return parser.parse_args()


def load_model_from_registry(model_name: str) -> Tuple[torch.nn.Module, list]:
    """
    Charge un mod√®le depuis le ClearML Model Registry.
    
    Returns:
        Tuple (model, classes)
    """
    print(f"Chargement du mod√®le '{model_name}' depuis le Model Registry...")
    
    input_model = InputModel(
        project=CLEARML_PROJECT_NAME,
        name=model_name
    )
    
    # T√©l√©charger les poids
    model_path = input_model.get_weights()
    
    # R√©cup√©rer les m√©tadonn√©es
    design = input_model.config_dict
    classes = design.get("classes", DEFAULT_CLASSES)
    architecture = design.get("architecture", "resnet18")
    num_classes = len(classes)
    
    # Charger le mod√®le
    model = create_model(
        num_classes=num_classes,
        pretrained=False,
        model_name=architecture
    )
    model.load_state_dict(torch.load(model_path, map_location=DEVICE))
    model.eval()
    
    print(f"‚úì Mod√®le charg√©: {architecture}, {num_classes} classes")
    return model, classes


def initialize_model(args) -> Tuple[torch.nn.Module, list]:
    """
    Initialise le mod√®le selon les arguments.
    
    Returns:
        Tuple (model, classes)
    """
    global DEVICE
    DEVICE = get_device()
    print(f"Device: {DEVICE}")
    
    if args.use_registry:
        return load_model_from_registry(args.model_name)
    
    elif args.model_path:
        model_path = Path(args.model_path)
        if not model_path.exists():
            raise FileNotFoundError(f"Mod√®le non trouv√©: {model_path}")
        model, metadata = load_model(model_path, device=DEVICE)
        classes = metadata.get("classes", DEFAULT_CLASSES) if metadata else DEFAULT_CLASSES
        return model, classes
    
    else:
        # Chercher le dernier mod√®le local
        model_path = get_latest_model_path()
        if model_path:
            print(f"Utilisation du dernier mod√®le local: {model_path}")
            model, metadata = load_model(model_path, device=DEVICE)
            # Valider les classes - ignorer si ce sont des noms de dossiers incorrects
            if metadata and "classes" in metadata:
                detected_classes = metadata["classes"]
                # V√©rifier si les classes sont valides (pas train/val)
                if "train" in detected_classes or "val" in detected_classes:
                    print(f"‚ö†Ô∏è  Classes invalides d√©tect√©es: {detected_classes}")
                    print(f"    Utilisation des classes par d√©faut: {DEFAULT_CLASSES}")
                    classes = DEFAULT_CLASSES
                else:
                    classes = detected_classes
            else:
                classes = DEFAULT_CLASSES
            return model, classes
        else:
            # Mode d√©mo sans mod√®le r√©el
            print("‚ö†Ô∏è  Aucun mod√®le trouv√©. Mode d√©monstration...")
            model = create_model(num_classes=len(DEFAULT_CLASSES), pretrained=True)
            model.to(DEVICE)
            model.eval()
            return model, DEFAULT_CLASSES


# =============================================================================
# FONCTIONS DE PR√âDICTION ET FEEDBACK
# =============================================================================

def predict(image: Image.Image) -> str:
    """
    Effectue une pr√©diction sur une image.
    
    Args:
        image: Image PIL
        
    Returns:
        String avec les pr√©dictions et probabilit√©s
    """
    global MODEL, CLASSES, DEVICE, TASK
    
    if image is None:
        return "Veuillez fournir une image."
    
    try:
        # Pr√©processer l'image
        input_tensor = preprocess_image(image, for_training=False)
        input_batch = input_tensor.unsqueeze(0).to(DEVICE)
        
        # Pr√©diction
        with torch.no_grad():
            outputs = MODEL(input_batch)
            probabilities = torch.nn.functional.softmax(outputs[0], dim=0)
        
        # Formater les r√©sultats
        results = []
        sorted_indices = torch.argsort(probabilities, descending=True)
        
        for idx in sorted_indices[:3]:  # Top 3
            class_name = CLASSES[idx]
            prob = probabilities[idx].item() * 100
            results.append(f"‚Ä¢ {class_name}: {prob:.1f}%")
        
        predicted_class = CLASSES[sorted_indices[0]]
        prediction_text = f"**Pr√©diction: {predicted_class}**\n\n" + "\n".join(results)
        
        # Log dans ClearML si une t√¢che est active
        if TASK:
            TASK.get_logger().report_text(
                f"Prediction: {predicted_class}",
                print_console=False
            )
        
        return prediction_text
        
    except Exception as e:
        return f"Erreur de pr√©diction: {str(e)}"


def get_predicted_class(image: Image.Image) -> str:
    """Retourne uniquement la classe pr√©dite."""
    global MODEL, CLASSES, DEVICE
    
    if image is None:
        return ""
    
    try:
        input_tensor = preprocess_image(image, for_training=False)
        input_batch = input_tensor.unsqueeze(0).to(DEVICE)
        
        with torch.no_grad():
            outputs = MODEL(input_batch)
            _, predicted = outputs.max(1)
        
        return CLASSES[predicted.item()]
    except:
        return ""


def handle_feedback(
    image: Image.Image,
    true_label: str,
    prediction_display: str
) -> str:
    """
    Enregistre le feedback utilisateur.
    
    Args:
        image: Image PIL
        true_label: Label correct fourni par l'utilisateur
        prediction_display: Affichage de la pr√©diction (pour extraire la classe pr√©dite)
        
    Returns:
        Message de confirmation
    """
    global TASK
    
    if image is None:
        return "‚ùå Veuillez d'abord charger une image."
    
    if not true_label or true_label.strip() == "":
        return "‚ùå Veuillez s√©lectionner ou saisir le label correct."
    
    true_label = true_label.strip().lower().replace(" ", "_")
    
    # R√©cup√©rer la pr√©diction
    predicted_label = get_predicted_class(image)
    if not predicted_label:
        predicted_label = "unknown"
    
    try:
        # Sauvegarder l'image
        saved_path = save_feedback_image(image, true_label, predicted_label)
        
        # Log dans ClearML
        if TASK:
            is_correct = true_label == predicted_label
            TASK.get_logger().report_single_value(
                name="feedback_count",
                value=get_total_feedback_count()
            )
            TASK.get_logger().report_text(
                f"Feedback: predicted={predicted_label}, true={true_label}, correct={is_correct}",
                print_console=False
            )
        
        # Statistiques
        stats = count_feedback_images()
        total = get_total_feedback_count()
        
        return f"""‚úÖ **Feedback enregistr√© !**

‚Ä¢ Image sauvegard√©e: `{saved_path.name}`
‚Ä¢ Label: **{true_label}**
‚Ä¢ Pr√©diction originale: {predicted_label}
‚Ä¢ Total feedbacks collect√©s: **{total}**

_Cette image sera utilis√©e pour am√©liorer le mod√®le lors du prochain r√©entra√Ænement._"""
        
    except Exception as e:
        return f"‚ùå Erreur lors de la sauvegarde: {str(e)}"


def get_feedback_stats() -> str:
    """Retourne les statistiques de feedback."""
    stats = count_feedback_images()
    total = get_total_feedback_count()
    
    if not stats:
        return "Aucun feedback collect√© pour le moment."
    
    lines = [f"**Total: {total} images**\n"]
    for class_name, count in sorted(stats.items()):
        lines.append(f"‚Ä¢ {class_name}: {count}")
    
    return "\n".join(lines)


# =============================================================================
# INTERFACE GRADIO
# =============================================================================

def create_interface(classes: List[str], share: bool = False, port: int = 7860):
    """Cr√©e et lance l'interface Gradio."""
    
    with gr.Blocks(
        title="Classification d'Images - MLOps"
    ) as demo:
        
        gr.Markdown("""
# üñºÔ∏è Classification d'Images - MLOps Demo

Uploadez une image pour obtenir une pr√©diction. Si la pr√©diction est incorrecte, 
vous pouvez fournir le label correct pour am√©liorer le mod√®le.
        """)
        
        with gr.Row():
            # Colonne gauche : Image et pr√©diction
            with gr.Column(scale=1):
                gr.Markdown("### üì§ Image √† classifier")
                image_input = gr.Image(
                    type="pil",
                    label="Charger une image",
                    sources=["upload", "clipboard", "webcam"]
                )
                predict_btn = gr.Button("üîç Pr√©dire", variant="primary")
                
                gr.Markdown("### üìä R√©sultat")
                prediction_output = gr.Markdown(
                    value="_Chargez une image et cliquez sur 'Pr√©dire'_"
                )
            
            # Colonne droite : Feedback
            with gr.Column(scale=1):
                gr.Markdown("### üìù Feedback (Correction)")
                gr.Markdown(
                    "_Si la pr√©diction est incorrecte, s√©lectionnez le bon label:_"
                )
                
                label_dropdown = gr.Dropdown(
                    choices=classes,
                    label="Label correct",
                    info="S√©lectionnez dans la liste ou tapez un nouveau label"
                )
                
                label_text = gr.Textbox(
                    label="Ou saisissez un nouveau label",
                    placeholder="ex: chat_persan"
                )
                
                feedback_btn = gr.Button("‚úÖ Envoyer le feedback", variant="secondary")
                
                feedback_output = gr.Markdown(value="")
                
                gr.Markdown("---")
                gr.Markdown("### üìà Statistiques de feedback")
                stats_output = gr.Markdown(value=get_feedback_stats())
                refresh_stats_btn = gr.Button("üîÑ Rafra√Æchir")
        
        gr.Markdown("""
---
### ‚ÑπÔ∏è Comment √ßa marche

1. **Uploadez** une image via drag & drop, presse-papier ou webcam
2. **Cliquez** sur "Pr√©dire" pour obtenir la classification
3. **Si la pr√©diction est incorrecte**, s√©lectionnez ou saisissez le bon label
4. **Envoyez** votre feedback - l'image sera sauvegard√©e pour le r√©entra√Ænement

_Les feedbacks sont collect√©s et utilis√©s pour cr√©er de nouvelles versions du dataset, 
ce qui d√©clenche automatiquement un r√©entra√Ænement du mod√®le via ClearML Pipeline._
        """)
        
        # √âv√©nements
        predict_btn.click(
            fn=predict,
            inputs=[image_input],
            outputs=[prediction_output]
        )
        
        # Pr√©diction automatique au chargement d'image
        image_input.change(
            fn=predict,
            inputs=[image_input],
            outputs=[prediction_output]
        )
        
        def submit_feedback(image, dropdown_label, text_label, prediction_display):
            # Priorit√© au dropdown, sinon au texte
            label = dropdown_label if dropdown_label else text_label
            return handle_feedback(image, label, prediction_display)
        
        feedback_btn.click(
            fn=submit_feedback,
            inputs=[image_input, label_dropdown, label_text, prediction_output],
            outputs=[feedback_output]
        )
        
        refresh_stats_btn.click(
            fn=get_feedback_stats,
            inputs=[],
            outputs=[stats_output]
        )
    
    return demo


# =============================================================================
# POINT D'ENTR√âE
# =============================================================================

def main():
    """Point d'entr√©e principal."""
    global MODEL, CLASSES, TASK
    
    args = parse_args()
    
    # Configuration ClearML
    setup_clearml_credentials()
    
    # Initialiser la t√¢che ClearML pour tracker les pr√©dictions
    TASK = Task.init(
        project_name=CLEARML_PROJECT_NAME,
        task_name="gradio_inference_app",
        task_type=Task.TaskTypes.inference
    )
    
    print("=" * 60)
    print("APPLICATION GRADIO - CLASSIFICATION D'IMAGES")
    print("=" * 60)
    
    # Charger le mod√®le
    MODEL, CLASSES = initialize_model(args)
    
    print(f"Classes: {CLASSES}")
    print(f"Feedback directory: {FEEDBACK_DIR}")
    print(f"Feedbacks existants: {get_total_feedback_count()}")
    print("=" * 60)
    
    # Cr√©er et lancer l'interface
    demo = create_interface(
        classes=CLASSES,
        share=args.share,
        port=args.port
    )
    
    print(f"\nüöÄ Lancement de l'interface sur http://localhost:{args.port}")
    if args.share:
        print("üì° Un lien public sera g√©n√©r√©...")
    
    demo.launch(
        server_port=args.port,
        share=args.share,
        show_error=True
    )


if __name__ == "__main__":
    main()
