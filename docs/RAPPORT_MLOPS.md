# Rapport de Projet MLOps
## Classification d'Images Cats vs Dogs avec ClearML

---

**Auteur :** Jean Olivier Lompo  
**Date :** 4 D√©cembre 2024  
**Cours :** MLOps - Machine Learning Operations

---

## Table des Mati√®res

1. [Introduction](#1-introduction)
2. [Architecture du Syst√®me](#2-architecture-du-syst√®me)
3. [Composants MLOps](#3-composants-mlops)
4. [Impl√©mentation Technique](#4-impl√©mentation-technique)
5. [Pipeline de R√©entra√Ænement](#5-pipeline-de-r√©entra√Ænement)
6. [R√©sultats et M√©triques](#6-r√©sultats-et-m√©triques)
7. [Conclusion](#7-conclusion)

---

## 1. Introduction

### 1.1 Contexte

Ce projet impl√©mente une cha√Æne MLOps compl√®te pour la classification binaire d'images (chats vs chiens) en utilisant **ClearML** comme plateforme d'orchestration. L'objectif est de d√©montrer les bonnes pratiques en mati√®re de Machine Learning Operations.

### 1.2 Objectifs

Les objectifs principaux de ce projet sont :

- Mettre en place un **pipeline d'entra√Ænement** automatis√©
- Impl√©menter une **boucle de feedback** utilisateur via interface web
- G√©rer le **versioning des datasets** de mani√®re tra√ßable
- Automatiser le **r√©entra√Ænement** lors de nouvelles donn√©es
- Utiliser un **Model Registry** pour la gestion des versions de mod√®les

### 1.3 Technologies Utilis√©es

| Technologie | R√¥le |
|-------------|------|
| **Python 3.11** | Langage de programmation |
| **PyTorch** | Framework de Deep Learning |
| **ClearML** | Plateforme MLOps (tracking, pipelines, registry) |
| **Gradio** | Interface utilisateur web |
| **ResNet-18** | Architecture du mod√®le CNN |

---

## 2. Architecture du Syst√®me

### 2.1 Vue d'Ensemble

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        ARCHITECTURE MLOPS                           ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                     ‚îÇ
‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
‚îÇ   ‚îÇ   Dataset    ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Training    ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ    Model     ‚îÇ      ‚îÇ
‚îÇ   ‚îÇ   ClearML    ‚îÇ     ‚îÇ   Script     ‚îÇ     ‚îÇ   Registry   ‚îÇ      ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
‚îÇ          ‚ñ≤                                         ‚îÇ               ‚îÇ
‚îÇ          ‚îÇ                                         ‚ñº               ‚îÇ
‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ
‚îÇ   ‚îÇ   Dataset    ‚îÇ                         ‚îÇ   Gradio     ‚îÇ       ‚îÇ
‚îÇ   ‚îÇ  Versioning  ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ   App        ‚îÇ       ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      Feedback           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ
‚îÇ          ‚ñ≤                                         ‚îÇ               ‚îÇ
‚îÇ          ‚îÇ                                         ‚îÇ               ‚îÇ
‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îÇ               ‚îÇ
‚îÇ   ‚îÇ   Watcher    ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   Pipeline   ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò               ‚îÇ
‚îÇ   ‚îÇ   Trigger    ‚îÇ     ‚îÇ   Retrain    ‚îÇ                          ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                          ‚îÇ
‚îÇ                                                                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 2.2 Structure du Projet

```text
mlops_clearml_project/
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ clearml.conf              # Configuration API ClearML
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ cats_vs_dogs/             # Dataset principal
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train/                # 25,000 images
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cat/              # 12,500 images
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ dog/              # 12,500 images
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ val/                  # Images de validation
‚îÇ   ‚îî‚îÄ‚îÄ feedback_labeled/         # Corrections utilisateurs
‚îú‚îÄ‚îÄ models/                       # Checkpoints locaux
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ utils.py                  # Fonctions utilitaires
‚îÇ   ‚îú‚îÄ‚îÄ download_dataset.py       # T√©l√©chargement dataset
‚îÇ   ‚îú‚îÄ‚îÄ train_baseline.py         # Entra√Ænement initial
‚îÇ   ‚îú‚îÄ‚îÄ gradio_app.py             # Interface web
‚îÇ   ‚îú‚îÄ‚îÄ dataset_versioning.py     # Gestion versions
‚îÇ   ‚îú‚îÄ‚îÄ pipeline_retrain.py       # Pipeline ClearML
‚îÇ   ‚îî‚îÄ‚îÄ watcher_trigger.py        # D√©tection automatique
‚îî‚îÄ‚îÄ requirements.txt
```

---

## 3. Composants MLOps

### 3.1 Entra√Ænement Initial (`train_baseline.py`)

Le script d'entra√Ænement de base utilise un mod√®le **ResNet-18** pr√©-entra√Æn√© sur ImageNet, avec fine-tuning pour la classification binaire.

**Formule de la fonction de perte (Cross-Entropy) :**

$$\mathcal{L}_{CE} = -\frac{1}{N}\sum_{i=1}^{N}\sum_{c=1}^{C} y_{i,c} \log(\hat{y}_{i,c})$$

O√π :
- $N$ = nombre d'√©chantillons
- $C$ = nombre de classes (2 pour cats/dogs)
- $y_{i,c}$ = label r√©el (one-hot)
- $\hat{y}_{i,c}$ = probabilit√© pr√©dite

**Hyperparam√®tres par d√©faut :**

| Param√®tre | Valeur |
|-----------|--------|
| Learning Rate | $\alpha = 0.001$ |
| Batch Size | 32 |
| Epochs | 10 |
| Optimizer | Adam |
| Scheduler | StepLR (step=5, $\gamma=0.5$) |

**Mise √† jour des poids (Adam) :**

$$m_t = \beta_1 m_{t-1} + (1-\beta_1) g_t$$
$$v_t = \beta_2 v_{t-1} + (1-\beta_2) g_t^2$$
$$\theta_t = \theta_{t-1} - \alpha \frac{m_t}{\sqrt{v_t} + \epsilon}$$

### 3.2 Interface Utilisateur (`gradio_app.py`)

L'interface Gradio permet :

1. **Pr√©diction** : Upload d'image ‚Üí Classification
2. **Feedback** : Correction du label si erreur
3. **Statistiques** : Visualisation des feedbacks collect√©s

**Flux de pr√©diction :**

$$\text{Image} \xrightarrow{\text{Preprocess}} \text{Tensor}_{224 \times 224} \xrightarrow{\text{ResNet}} \text{Logits} \xrightarrow{\text{Softmax}} P(\text{cat}), P(\text{dog})$$

**Normalisation des images :**

$$x_{norm} = \frac{x - \mu}{\sigma}$$

Avec $\mu = [0.485, 0.456, 0.406]$ et $\sigma = [0.229, 0.224, 0.225]$ (statistiques ImageNet).

#### 3.2.1 Extension Dynamique des Classes (Nouveau Label)

Une fonctionnalit√© cl√© de l'interface est la possibilit√© d'**ajouter de nouvelles classes** au mod√®le via le champ "Nouveau label". Cela permet le **Continuous Learning** :

**Cas d'usage :**
- Le mod√®le initial est entra√Æn√© sur 2 classes : `cat` et `dog`
- Un utilisateur uploade une image de **lapin** üê∞
- Le mod√®le pr√©dit "cat" (classe la plus proche)
- L'utilisateur corrige en saisissant "rabbit" dans le champ "Nouveau label"
- L'image est sauvegard√©e dans `data/feedback_labeled/rabbit/`

**Structure r√©sultante :**

```
data/feedback_labeled/
‚îú‚îÄ‚îÄ cat/           # Corrections vers "cat"
‚îú‚îÄ‚îÄ dog/           # Corrections vers "dog"
‚îî‚îÄ‚îÄ rabbit/        # üÜï Nouvelle classe cr√©√©e dynamiquement
```

**√âvolution du mod√®le :**

$$\text{Classes}_{v1} = \{\text{cat}, \text{dog}\} \xrightarrow{\text{feedback}} \text{Classes}_{v2} = \{\text{cat}, \text{dog}, \text{rabbit}\}$$

Lors du r√©entra√Ænement, le mod√®le adapte automatiquement sa couche de sortie :

$$\text{FC}: 512 \rightarrow 2 \quad \Rightarrow \quad \text{FC}: 512 \rightarrow 3$$

Cette approche permet une **am√©lioration continue** du mod√®le sans intervention manuelle sur le code.

### 3.3 Versioning des Donn√©es (`dataset_versioning.py`)

Le versioning ClearML permet de :

- Cr√©er des **versions incr√©mentales** du dataset
- Maintenir la **tra√ßabilit√©** via les datasets parents
- **Automatiser** l'upload des feedbacks collect√©s

**Sch√©ma de versioning :**

```
cats_vs_dogs_base (v1)
        ‚îÇ
        ‚ñº
cats_vs_dogs_feedback_v20241204_120000 (v2)
        ‚îÇ
        ‚ñº
cats_vs_dogs_feedback_v20241205_150000 (v3)
        ‚îÇ
        ‚ñº
       ...
```

### 3.4 Pipeline de R√©entra√Ænement (`pipeline_retrain.py`)

La pipeline ClearML se compose de 3 √©tapes :

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  prepare_data  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  train_model   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ register_model ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**√âtape 1 - Pr√©paration des donn√©es :**
- T√©l√©chargement du dataset depuis ClearML
- Analyse de la distribution des classes

**√âtape 2 - Entra√Ænement :**
- Fine-tuning du mod√®le
- Logging des m√©triques (loss, accuracy)

**√âtape 3 - Enregistrement :**
- Upload du mod√®le dans le Model Registry
- M√©tadonn√©es (accuracy, classes, architecture)

### 3.5 Watcher Automatique (`watcher_trigger.py`)

Le watcher surveille les nouveaux datasets et d√©clenche automatiquement la pipeline :

```python
if latest_dataset_id != last_processed_id:
    trigger_pipeline(latest_dataset_id)
    save_state(latest_dataset_id)
```

---

## 4. Impl√©mentation Technique

### 4.1 Mod√®le de Classification

**Architecture ResNet-18 modifi√©e :**

| Couche | Entr√©e | Sortie |
|--------|--------|--------|
| Conv1 + BN + ReLU + MaxPool | 3√ó224√ó224 | 64√ó56√ó56 |
| Layer1 (2 BasicBlocks) | 64√ó56√ó56 | 64√ó56√ó56 |
| Layer2 (2 BasicBlocks) | 64√ó56√ó56 | 128√ó28√ó28 |
| Layer3 (2 BasicBlocks) | 128√ó28√ó28 | 256√ó14√ó14 |
| Layer4 (2 BasicBlocks) | 256√ó14√ó14 | 512√ó7√ó7 |
| AdaptiveAvgPool | 512√ó7√ó7 | 512√ó1√ó1 |
| **FC (modifi√©e)** | 512 | **2** |

**Nombre de param√®tres :**

$$\text{Total} \approx 11.2M \text{ param√®tres}$$

### 4.2 Augmentation de Donn√©es

| Transformation | Param√®tres |
|----------------|------------|
| Resize | 224√ó224 |
| RandomHorizontalFlip | $p=0.5$ |
| RandomRotation | $\pm 15¬∞$ |
| ColorJitter | brightness=0.2, contrast=0.2, saturation=0.2 |

### 4.3 M√©triques d'√âvaluation

**Accuracy :**

$$\text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN}$$

**Precision et Recall :**

$$\text{Precision} = \frac{TP}{TP + FP}$$

$$\text{Recall} = \frac{TP}{TP + FN}$$

**F1-Score :**

$$F_1 = 2 \cdot \frac{\text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}$$

---

## 5. Pipeline de R√©entra√Ænement

### 5.1 D√©clenchement Automatique

Le watcher d√©tecte les nouvelles versions de dataset selon l'algorithme :

```
D√âBUT
‚îÇ
‚îú‚îÄ‚îÄ Charger √©tat pr√©c√©dent (last_processed_id)
‚îÇ
‚îú‚îÄ‚îÄ R√©cup√©rer dernier dataset ClearML
‚îÇ
‚îú‚îÄ‚îÄ SI nouveau_id ‚â† last_processed_id ALORS
‚îÇ   ‚îú‚îÄ‚îÄ D√©clencher pipeline(nouveau_id)
‚îÇ   ‚îî‚îÄ‚îÄ Sauvegarder √©tat(nouveau_id)
‚îÇ
‚îî‚îÄ‚îÄ FIN
```

### 5.2 Configuration ClearML

```python
api {
    web_server: https://app.clear.ml/
    api_server: https://api.clear.ml
    files_server: https://files.clear.ml
    credentials {
        access_key = "..."
        secret_key = "..."
    }
}
```

### 5.3 D√©corateurs Pipeline

```python
@PipelineDecorator.component(cache=True)
def prepare_data(dataset_id: str) -> dict:
    ...

@PipelineDecorator.component(cache=False)
def train_model(data_info: dict, epochs: int) -> dict:
    ...

@PipelineDecorator.pipeline(name="AutoRetrain", project="MLOps_CatsVsDogs")
def retrain_pipeline(dataset_id: str, epochs: int = 10):
    data_info = prepare_data(dataset_id)
    train_result = train_model(data_info, epochs)
    register_model(train_result, dataset_id)
```

---

## 6. R√©sultats et M√©triques

### 6.1 Performance du Mod√®le Baseline

| M√©trique | Valeur |
|----------|--------|
| Validation Accuracy | ~95% |
| Training Loss | ~0.15 |
| Validation Loss | ~0.18 |
| Temps d'entra√Ænement | ~30 min (GPU) |

### 6.2 Courbes d'Apprentissage

**√âvolution de la loss :**

$$\mathcal{L}(t) = \mathcal{L}_0 \cdot e^{-\lambda t} + \mathcal{L}_{\infty}$$

O√π :
- $\mathcal{L}_0$ = loss initiale
- $\lambda$ = taux de convergence
- $\mathcal{L}_{\infty}$ = loss asymptotique

### 6.3 Analyse du Feedback

La boucle de feedback am√©liore it√©rativement le mod√®le :

$$\text{Accuracy}_{n+1} = \text{Accuracy}_n + \Delta_{\text{feedback}}$$

O√π $\Delta_{\text{feedback}}$ d√©pend de la qualit√© et quantit√© des corrections.

---

## 7. Conclusion

### 7.1 R√©alisations

Ce projet d√©montre une impl√©mentation compl√®te des pratiques MLOps :

‚úÖ **Tracking des exp√©riences** avec ClearML  
‚úÖ **Versioning des donn√©es** et des mod√®les  
‚úÖ **Pipeline automatis√©e** de r√©entra√Ænement  
‚úÖ **Boucle de feedback** utilisateur  
‚úÖ **Model Registry** centralis√©  

### 7.2 Avantages de l'Approche

| Aspect | B√©n√©fice |
|--------|----------|
| **Reproductibilit√©** | Chaque exp√©rience est tra√ßable |
| **Automatisation** | R√©entra√Ænement sans intervention |
| **Collaboration** | Interface ClearML partag√©e |
| **Am√©lioration continue** | Feedback ‚Üí Donn√©es ‚Üí Meilleur mod√®le |

### 7.3 Perspectives

- D√©ploiement sur **Kubernetes** avec ClearML Serving
- Ajout de **tests automatis√©s** (data validation, model validation)
- Int√©gration de **monitoring** en production
- Extension √† la **classification multi-classes**

---

## Annexes

### A. Commandes Principales

```bash
# Installation
pip install -r requirements.txt

# T√©l√©chargement dataset
python src/download_dataset.py

# Entra√Ænement
python src/train_baseline.py --data-path data/cats_vs_dogs --epochs 10

# Interface Gradio
python src/gradio_app.py

# Versioning dataset
python src/dataset_versioning.py --add-feedback

# Watcher
python src/watcher_trigger.py --watch
```

### B. R√©f√©rences

1. He, K., et al. "Deep Residual Learning for Image Recognition." CVPR 2016.
2. Kingma, D. P., & Ba, J. "Adam: A Method for Stochastic Optimization." ICLR 2015.
3. ClearML Documentation: https://clear.ml/docs/

---

*Rapport g√©n√©r√© le 4 D√©cembre 2024*
